
<p align="center">
<img center src="./assert/Framework.jpg" width = "700" alt="MLLM-Tuning">
</p>

<h1 align="center">Awesome-MLLM-Tuning </h1>

<p align="center"><em>Curated list of Multimodal Large Language Model (MLLM) Tuning resources, aligned with our work:</em><br><strong>Keeping Yourself is Important in Downstream Tuning Multimodal Large Language Model</strong></p>

<p align="center">
<a href="https://arxiv.org/abs/2503.04543"><img src="https://img.shields.io/badge/arXiv-2502.14881-b31b1b.svg" alt="arXiv Badge"></a>
<!--     <a href="https://awesome.re"><img src="https://awesome.re/badge.svg" alt="Awesome Badge"></a> -->
    <img src="https://badges.toozhao.com/badges/01JNMP5KB247X0F52D94216CT0/blue.svg" alt="Custom Badge" />
    <a href="https://creativecommons.org/licenses/by-nc/4.0/"><img src="https://img.shields.io/badge/License-CC_BY--NC_4.0-lightgrey.svg" alt="License Badge"></a>
    <a href="https://github.com/WenkeHuang/Awesome-MLLM-Tuning"><img src="https://img.shields.io/github/stars/WenkeHuang/Awesome-MLLM-Tuning?style=social" alt="GitHub stars"></a>
</p>

<h2> ðŸ™Œ Abstract </h2>
Multi-modal Large Language Models (MLLMs) integrate visual and linguistic reasoning to address complex tasks such as
image captioning and visual question answering. While MLLMs demonstrate remarkable versatility, MLLMs appears limited
performance on special application. But tuning MLLMs for downstream tasks encounters two key challenges: Task-Expert
Specialization, where distribution shifts between pre-training and target datasets constrain target performance, and Open-
World Stabilization, where catastrophic forgetting erases the model general knowledge. In this work, we systematically
review recent advancements in MLLM tuning methodologies, classifying them into three paradigms: (I) Selective Tuning, (II)
Additive Tuning, and (III) Reparameterization Tuning. Furthermore, we benchmark these tuning strategies across popular
MLLM architectures and diverse downstream tasks to establish standardized evaluation analysis and systematic tuning
principles. Finally, we highlight several open challenges in this domain and propose future research directions. 


